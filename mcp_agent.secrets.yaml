# ==============================================================================
# LLM Provider API Keys Configuration
# ==============================================================================
# HOW PROVIDER SELECTION WORKS:
# 1. Set your preferred provider in mcp_agent.config.yaml (llm_provider: "...")
# 2. The system tries your preferred provider first
# 3. If unavailable, it automatically falls back to other configured providers
# 4. You can configure multiple providers as backup options
#
# TIPS:
# - Configure at least 2 providers for reliability
# - OpenRouter gives access to many models with one API key
# - Ollama runs locally and is free (no API key needed)
# ==============================================================================

openai:
  api_key: ""
  base_url: ""  # Optional: for OpenAI-compatible endpoints

anthropic:
  api_key: ""

google:
  api_key: ""

openrouter:
  api_key: ""  # Get free key at https://openrouter.ai/
  base_url: "https://openrouter.ai/api/v1"

ollama:
  base_url: "http://localhost:11434/v1"  # Ollama OpenAI-compatible API endpoint (no API key needed)
  api_key: "ollama"  # Dummy key required by OpenAI client
